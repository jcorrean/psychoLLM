# First Case: Google's Gemini-generated items

Here, we are going to read a pool of psychometric items generated by Google's Gemini LLM.

```{r}
library(readr)
GeminiTest <- read_csv("Data/GeminiTest.csv")
```

Then, we proceed to parse the textual information as a corpus (i.e., a group of texts; in this case, a set of items).
```{r}
library(quanteda)
GeminiItems <- corpus(GeminiTest$generated.item)
summary(GeminiItems)
ItemsData <- data.frame(summary(GeminiItems, n = length(GeminiItems)))

Items <- tokens(GeminiItems, 
                remove_numbers = TRUE, 
                remove_punct = TRUE, 
                remove_url = TRUE, 
                remove_symbols = TRUE) %>%  
  tokens_remove(stopwords("english"))
GEMINIItems <- dfm(Items, tolower = TRUE)
```

Now, let's test empirically whether these items have a "textual dimensionality," (i.e., if the structure of language manifests several dimensions).

```{r}
library(hopkins)
Hopkins <- hopkins(ItemsData[c(2:4)])
Hopkins
hopkins.pval(Hopkins, n = 20)
```

The Hopkins statistic should be below the threshold of 0.5 to consider that the matrix is clusterable. Thus, the generated items, treated as a corpus can not be regarded as a linguistic corpus that can be split into several dimensions.


```{r}
Hopkins.Items <- hopkins(as.matrix(GEMINIItems))
Hopkins.Items
hopkins.pval(Hopkins.Items, n = 20)
```

Once again, the items generated by Gemini are, indeed, unclusterable, as the Hopkins
statistic still remain above the 0.5 threshold. Thus, these 20 items are not measuring several dimensions, at least, semantically.