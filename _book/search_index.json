[["index.html", "Informational Analysis of LLM-generated Psychometric Items Motivation", " Informational Analysis of LLM-generated Psychometric Items Juan C. Correa Critical Centrality Institute jcc@criticalcentrality.com 2024-07-04 Motivation Everyone has heard about “Large Language Models” (LLMs). These models rely on a generative artificial intelligence technology known as “Generative Pre-Trained Transformer.” Such technology is the foundational basis of “ChatGPT” (Mitchell and Krakauer 2023). For applied psychologists in general and psychometricians in particular, LLMs can be useful for psychometric items generation. Unfortunately, the empirical evidence for such purposes is scarce, until now. Here, I report a short piece of empirical evidence that shows how psychologists can apply “information theory” to grasp a quantitative metric of the quality of these items as compared to those generated by humans. Technology and software libraries For our particular purpose, we rely on the following R packages readr quanteda hopkins bookdown entropy These packages were used as a small RMarkdown-based project with Rstudio and Netlify. References Mitchell, Melanie, and David C Krakauer. 2023. “The debate over understanding in AI’s large language models.” Proceedings of the National Academy of Sciences 120 (13): e2215907120. https://doi.org/10.1073/pnas.2215907120. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
